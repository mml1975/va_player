**query_dataset directory**
----------------------

**audio_assistant_queries.csv** - contains `Request`: a query to the model, and `Response`: the ground truth answer.
                              The file was created by merging files generated by two programs,
                              `query_gen2.py` and `query_gen_control.py`, which produce synthetic queries and answers.

**gemma_audio_va_result2.json** - contains a dataset with entries: query text, ground truth answer, and the model's actual response.
                              The actual response was obtained in the `textrq.ipynb` program.

**audioplayer_va** - contains a dataset with TTS-generated audio of the query texts in two voices (male, female).
                 The accompanying header file `audioplayer_va.csv` contains:
                 `user_text` - the query text,
                 `user_audio` - the name of the wav file,
                 `assistant_text` - the ground truth answer (from `gemma_audio_va_result2.json`).
                 Generation was performed in `tts_gen.ipynb`.

**voice1example directory**
---------------------

**audioplayer_va_asr.csv** - Using `audioplayer_va.csv` and the wav files in `audioplayer_va`, the model received
                         audio files as input and generated a `tool_call` record. This is the same as in
                         `textrq.ipynb`, but directly from wav files. The result contains:
                         `user_text` - the query text,
                         `user_audio` - the name of the wav file,
                         `assistant_text` - the ground truth answer (from `gemma_audio_va_result2.json`)
                         `asr_text` - the model's response to the wav file.
                         Generation used the `voice1.ipynb` program (which also contains an example of an `audioplay` call).

////////

apt-get install libportaudio2

pip install flask pygame

**Program features:**

*   Asynchronous playback - does not block the main thread.
*   Two operating modes:
    *   `/tts/speak` - generation and immediate playback.
    *   `/tts/generate` - generation only, returning a WAV file.
*   Support for different languages (via the `language` parameter).
*   Ability to stop current playback.
*   Service health check.
*   Configuration via JSON file or default parameters.
*   Logging of all operations.

The service uses the XTTS v2 model, which supports multiple languages and allows voice cloning from a small audio file.

----------------

**pipeline1 directory**
-------------------

A primitive voice-controlled music player pipeline.
The `va_ver1.ipynb` program accepts...


**There is an issue:** Often misrecognizes song titles. Need to improve the database search algorithm. Add fuzzy search. Including Russian written in Latin script and vice versa.
Often reports `play_back stopped` when it's not stopped.

Quality depends on the microphone input level. Compromise: lower level - better at isolating speech; if the level is too high, it may start recognizing the music itself. 90% seems decent.
