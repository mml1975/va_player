import torch
import sounddevice as sd
import wavio
import numpy as np
from silero_vad import load_silero_vad
import time

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–¥–∏–æ
SAMPLE_RATE = 16000
CHUNK_SIZE = 512  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ 16 –∫–ì—Ü
CHUNK_DURATION_MS = int((CHUNK_SIZE / SAMPLE_RATE) * 1000)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ü–∞ —Ä–µ–ø–ª–∏–∫–∏
PAUSE_THRESHOLD_MS = 500
PAUSE_CHUNKS = PAUSE_THRESHOLD_MS // CHUNK_DURATION_MS

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
model = load_silero_vad()
model.eval()

# –°–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–ø–∏—Å–∏
audio_buffer = []
is_recording = False
pause_counter = 0

def callback(indata, frames, time_info, status):
    global audio_buffer, is_recording, pause_counter
    
    if status:
        print(f"–ê—É–¥–∏–æ—Å—Ç–∞—Ç—É—Å: {status}")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
    if indata.ndim > 1:
        audio_chunk = indata.mean(axis=1).flatten()
    else:
        audio_chunk = indata.flatten()
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ: —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–æ–≤–Ω–æ 512 —Å–µ–º–ø–ª–æ–≤
    if len(audio_chunk) > CHUNK_SIZE:
        audio_chunk = audio_chunk[:CHUNK_SIZE]
    elif len(audio_chunk) < CHUNK_SIZE:
        # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ (—Ç–∏—à–∏–Ω–æ–π) –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        padding = np.zeros(CHUNK_SIZE - len(audio_chunk))
        audio_chunk = np.concatenate([audio_chunk, padding])
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä PyTorch –∏ –ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–µ—á–∏
    audio_tensor = torch.from_numpy(audio_chunk).float()
    
    with torch.no_grad():
        # –ú–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –≤—Ö–æ–¥ [batch_size, samples]
        # unsqueeze(0) –¥–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞
        prob_tensor = model(audio_tensor.unsqueeze(0), SAMPLE_RATE)
        
        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å:
        # print(f"–§–æ—Ä–º–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π: {prob_tensor.shape}, –∑–Ω–∞—á–µ–Ω–∏—è: {prob_tensor}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–∫–∞–ª—è—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        # –ï—Å–ª–∏ prob_tensor –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É [1, 1], –∏—Å–ø–æ–ª—å–∑—É–µ–º .item()
        # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞ [1, n], –Ω—É–∂–Ω–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–∑—è—Ç—å —Å—Ä–µ–¥–Ω–µ–µ)
        if prob_tensor.numel() == 1:
            speech_prob = prob_tensor.item()
        else:
            # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ñ—Ä–µ–π–º–∞–º
            speech_prob = prob_tensor.mean().item()
    
    # –õ–æ–≥–∏–∫–∞ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏ –∑–∞–ø–∏—Å–∏
    if speech_prob > 0.5:  # –ü–æ—Ä–æ–≥ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å (–æ–±—ã—á–Ω–æ 0.5)
        is_recording = True
        pause_counter = 0
        audio_buffer.append(audio_chunk.copy())
        print("üé§ –†–µ—á—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞", end='\r')
    elif is_recording:
        pause_counter += 1
        audio_buffer.append(audio_chunk.copy())
        
        if pause_counter >= PAUSE_CHUNKS:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω—É—é —Ä–µ–ø–ª–∏–∫—É
            if audio_buffer:
                full_audio = np.concatenate(audio_buffer, axis=0)
                timestamp = int(time.time() * 1000)
                filename = f"utterance_{timestamp}.wav"
                wavio.write(filename, full_audio, SAMPLE_RATE, sampwidth=2)
                duration = len(full_audio) / SAMPLE_RATE
                print(f"\n‚úÖ –†–µ–ø–ª–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filename} ({duration:.2f} —Å–µ–∫)")
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Ä–µ–ø–ª–∏–∫–∏
                audio_buffer.clear()
                is_recording = False
                pause_counter = 0

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∑–∞–ø—É—Å–∫ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞
print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: –ß–∞—Å—Ç–æ—Ç–∞ {SAMPLE_RATE} –ì—Ü, —á–∞–Ω–∫ {CHUNK_SIZE} —Å–µ–º–ø–ª–æ–≤")
print(f"–ü–æ—Ä–æ–≥ –ø–∞—É–∑—ã: {PAUSE_THRESHOLD_MS} –º—Å")

try:
    stream = sd.InputStream(
        channels=1,
        samplerate=SAMPLE_RATE,
        blocksize=CHUNK_SIZE,
        callback=callback,
        dtype='float32'
    )
    
    stream.start()
    print("\nüé§ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ... (Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)")
    print("–ò–Ω–¥–∏–∫–∞—Ü–∏—è: 'üé§ –†–µ—á—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞' –ø—Ä–∏ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–µ—á–∏")
    
    # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –æ–∂–∏–¥–∞–Ω–∏—è
    while True:
        time.sleep(0.1)
        
except KeyboardInterrupt:
    print("\n\n–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
except Exception as e:
    print(f"\n–û—à–∏–±–∫–∞: {e}")
finally:
    if 'stream' in locals():
        stream.stop()
        stream.close()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–ø–ª–∏–∫—É, –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –≤–æ –≤—Ä–µ–º—è —Ä–µ—á–∏
    if audio_buffer and is_recording:
        full_audio = np.concatenate(audio_buffer, axis=0)
        filename = f"utterance_final_{int(time.time()*1000)}.wav"
        wavio.write(filename, full_audio, SAMPLE_RATE, sampwidth=2)
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Ä–µ–ø–ª–∏–∫–∞: {filename}")
